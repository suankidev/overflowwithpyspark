{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d870135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', <pyspark.resultiterable.ResultIterable at 0x1df2fdda370>),\n",
       " ('A', <pyspark.resultiterable.ResultIterable at 0x1df2fdda400>),\n",
       " ('B', <pyspark.resultiterable.ResultIterable at 0x1df2fdda460>)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"C:\\\\Users\\\\sujee\\\\pydev\\\\pyspark_learn_project\\\\common_utils\")\n",
    "\n",
    "from sparkUtils import get_spark_session\n",
    "spark = get_spark_session()\n",
    "\n",
    "path = \"C:\\\\Users\\\\sujee\\\\pydev\\\\pyspark_learn_project\\\\resources\"\n",
    "flight_path = path + \"\\\\spark_input\\\\flight_data\\\\2015-summary.csv\"\n",
    "readme_path = path + \"\\\\spark_input\\\\README.txt\"\n",
    "my_collection = \"Spark The Definitive Guide : Big Data Processing Made Simple The\".split(\" \")\n",
    "        \n",
    "\n",
    "my_coll = spark.sparkContext.parallelize(my_collection, 2)\n",
    "\n",
    "read_rdd= spark.sparkContext.textFile(readme_path)\n",
    "\n",
    "#reading plaing readme file\n",
    "# read_rdd.flatMap(lambda x: x.split(\" \")).map(lambda x: (1, x)).filter(lambda x: x[1].lower() == 'user'\n",
    "\n",
    "\n",
    "row = [('A',),('B',),('C',),('B',)]\n",
    "word = spark.sparkContext.parallelize(row, 2)\n",
    "\n",
    "\n",
    "\n",
    "file_rdd = spark.sparkContext.textFile(flight_path)\n",
    "\n",
    "#file_rdd.take(5)\n",
    "from functools import reduce\n",
    "word.flatMap(lambda x: x).map(lambda x: (x,1)).groupByKey().collect()\n",
    "\n",
    "#.map(lambda x: (x[0], reduce(lambda x,y: x+y, x[1])))\\\n",
    "#.filter(lambda x: x[0] == 'B').collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6efac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', [1]), ('A', [1]), ('B', [1, 1])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.flatMap(lambda x: x).map(lambda x: (x,1)).groupByKey().map(lambda x: (x[0], list(x[1]))).collect()\n",
    "\n",
    "#.map(lambda x: (x[0], reduce(lambda x,y: x+y, x[1])))\\\n",
    "#.filter(lambda x: x[0] == 'B').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a0397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 1), ('A', 1), ('B', 2)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.flatMap(lambda x: x).map(lambda x: (x,1)).groupByKey()\\\n",
    "         .map(lambda x: (x[0], sum(list(x[1])))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4032b66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reading csv file in rdd\n",
    "\n",
    "file_rdd = spark.sparkContext.textFile(flight_path)\n",
    "file_df = spark.read.csv(flight_path,header=True)\n",
    "\n",
    "\n",
    "\n",
    "#find the no of flight from US to INDIA in RDD and structured API\n",
    "\n",
    "\n",
    "file_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07914ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|check|\n",
      "+-----------------+-------------------+-----+-----+\n",
      "|            India|      United States|   61| true|\n",
      "+-----------------+-------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "#find no of flight from Unitest States to India\n",
    "origin_c = col('ORIGIN_COUNTRY_NAME') == 'United States'\n",
    "dest_c = col('DEST_COUNTRY_NAME') == 'India'\n",
    "\n",
    "file_df.select(col(\"*\"), (origin_c & dest_c).alias('check')).filter(col('check') == True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeac22a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['United States', 'India', '62']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_rdd_1 = file_rdd.map(lambda x:x.split(\",\"))\n",
    "\n",
    "file_rdd_2 = file_rdd_1.filter(lambda x: x[0] != 'DEST_COUNTRY_NAME' )\\\n",
    "             .filter(lambda x: x[0] == 'United States' and x[1] == 'India')\n",
    "\n",
    "\n",
    "file_rdd_2.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33be7318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 'S'),\n",
       " ('s', 'P'),\n",
       " ('s', 'A'),\n",
       " ('s', 'R'),\n",
       " ('s', 'K'),\n",
       " ('t', 'T'),\n",
       " ('t', 'H'),\n",
       " ('t', 'E'),\n",
       " ('d', 'D'),\n",
       " ('d', 'E'),\n",
       " ('d', 'F'),\n",
       " ('d', 'I'),\n",
       " ('d', 'N'),\n",
       " ('d', 'I'),\n",
       " ('d', 'T'),\n",
       " ('d', 'I'),\n",
       " ('d', 'V'),\n",
       " ('d', 'E'),\n",
       " ('g', 'G'),\n",
       " ('g', 'U'),\n",
       " ('g', 'I'),\n",
       " ('g', 'D'),\n",
       " ('g', 'E'),\n",
       " (':', ':'),\n",
       " ('b', 'B'),\n",
       " ('b', 'I'),\n",
       " ('b', 'G'),\n",
       " ('d', 'D'),\n",
       " ('d', 'A'),\n",
       " ('d', 'T'),\n",
       " ('d', 'A'),\n",
       " ('p', 'P'),\n",
       " ('p', 'R'),\n",
       " ('p', 'O'),\n",
       " ('p', 'C'),\n",
       " ('p', 'E'),\n",
       " ('p', 'S'),\n",
       " ('p', 'S'),\n",
       " ('p', 'I'),\n",
       " ('p', 'N'),\n",
       " ('p', 'G'),\n",
       " ('m', 'M'),\n",
       " ('m', 'A'),\n",
       " ('m', 'D'),\n",
       " ('m', 'E'),\n",
       " ('s', 'S'),\n",
       " ('s', 'I'),\n",
       " ('s', 'M'),\n",
       " ('s', 'P'),\n",
       " ('s', 'L'),\n",
       " ('s', 'E'),\n",
       " ('t', 'T'),\n",
       " ('t', 'H'),\n",
       " ('t', 'E')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#my_coll.map(lambda x: x.split(\" \")).collect()\n",
    "\n",
    "my_coll.map(lambda x: (x.lower(), 1)).collect()\n",
    "\n",
    "keyword = my_coll.keyBy(lambda x: x.lower()[0])\n",
    "\n",
    "\n",
    "map_value = keyword.mapValues(lambda x: x.upper())\n",
    "\n",
    "flat_map_value = keyword.flatMapValues(lambda x: x.upper())\n",
    "\n",
    "flat_map_value.collect()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58e7261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', 't', 'd', 'g', ':', 'b', 'd', 'p', 'm', 's', 't']\n",
      "['Spark', 'The', 'Definitive', 'Guide', ':', 'Big', 'Data', 'Processing', 'Made', 'Simple', 'The']\n"
     ]
    }
   ],
   "source": [
    "print(keyword.keys().collect(), keyword.values().collect(),sep=\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17762dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'Simple']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#look up for key will return list of values with matched key\n",
    "keyword.lookup('s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76993b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = my_coll.flatMap(lambda x: x.lower())\n",
    "KVChar = my_coll.map(lambda x: (x, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df91dec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s',\n",
       " 'p',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'i',\n",
       " 'n',\n",
       " 'i',\n",
       " 't',\n",
       " 'i',\n",
       " 'v',\n",
       " 'e',\n",
       " 'g',\n",
       " 'u',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " ':',\n",
       " 'b',\n",
       " 'i',\n",
       " 'g',\n",
       " 'd',\n",
       " 'a',\n",
       " 't',\n",
       " 'a',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'c',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'm',\n",
       " 'a',\n",
       " 'd',\n",
       " 'e',\n",
       " 's',\n",
       " 'i',\n",
       " 'm',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " 't',\n",
       " 'h',\n",
       " 'e']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9e19001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Spark': 1,\n",
       "             'The': 2,\n",
       "             'Definitive': 1,\n",
       "             'Guide': 1,\n",
       "             ':': 1,\n",
       "             'Big': 1,\n",
       "             'Data': 1,\n",
       "             'Processing': 1,\n",
       "             'Made': 1,\n",
       "             'Simple': 1})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVChar.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7266ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.defaultdict'> 2\n"
     ]
    }
   ],
   "source": [
    "demo = KVChar.countByKey()\n",
    "\n",
    "\n",
    "print(type(demo), demo.get('The'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdb0fd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spark', 1),\n",
       " ('The', 2),\n",
       " ('Made', 1),\n",
       " ('Definitive', 1),\n",
       " ('Guide', 1),\n",
       " (':', 1),\n",
       " ('Big', 1),\n",
       " ('Data', 1),\n",
       " ('Processing', 1),\n",
       " ('Simple', 1)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "#def addFunc():\n",
    "kvchar_group = KVChar.groupByKey().map(lambda row: (row[0], reduce(lambda x,y: x+y, row[1])))\n",
    "\n",
    "kvchar_group.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "464c8a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 2)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kvchar_group.filter(lambda x: x[0] == 'The').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0116c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
